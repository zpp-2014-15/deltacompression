% Niniejszy plik stanowi przyk³ad formatowania pracy magisterskiej na Wydziale MIM UW.  Szkielet u¿ytych poleceñ mo¿na wykorzystywaæ do woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrze¿one.
%
% Copyright (c) 2001 by Marcin Woliñski <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie 
% - Seweryn Kar³owicz, 05.05.2006
% dodaj opcjê [licencjacka] dla pracy licencjackiej
\documentclass[licencjacka]{styles}

\usepackage{polski}
\usepackage{url}
\usepackage{graphicx}
\usepackage{pgffor}
\usepackage{amsmath}
\usepackage{algpseudocode}
\urlstyle{same}

%Jesli uzywasz kodowania polskich znakow ISO-8859-2 nastepna linia powinna byc odkomentowana
%\usepackage[latin2]{inputenc}
%Jesli uzywasz kodowania polskich znakow CP-1250 to ta linia powinna byc  odkomentowana
\usepackage[cp1250]{inputenc}

% Uwaga: ka¿dy z nas czworga ma oddzielny egzemplarz i wpisuje swoje dane
\author{Imiê i nazwisko}

\nralbumu{6 cyfr}

\title{Optymalizacja ruchu sieciowego w symulowanym systemie rozproszonych kopii zapasowych}

\tytulang{Optimization of network traffic in distributed backup systems}

\kierunek{Informatyka}

% Praca wykonana pod kierunkiem:
% (podaæ tytu³/stopieñ imiê i nazwisko opiekuna
% Instytut
% ew. Wydzia³ ew. Uczelnia (je¿eli nie MIM UW))
\opiekun{dra Roberta D¹browskiego\\
  Instytut Informatyki\\
  }

% miesi¹c i~rok:
\date{Czerwiec 2015}

%Podaæ dziedzinê wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
11.3 Informatyka\\ 
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{
	10002951 Information systems\\
	10002951.10003152.10003517.10003519 Distributed storage\\
  10002951.10002952.10002971.10003451.10002975 Data compression
  }
% S³owa kluczowe:
\keywords{delta kodowanie, indeks podobieñstwa, optymalizacja ruchu sieciowego, rozproszony system kopii zapasowych}

% Tu jest dobre miejsce na Twoje w³asne makra i~œrodowiska:
\newtheorem{defi}{Definicja}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
W pracy przedstawiono opis symulatora rozproszonych kopii zapasowych, algorytmów delta kodowania oraz wyniki przeprowadzonych eksperymentów.
Symulator naœladuje pracê systemu HYDRAstor oraz pozwala na zbadanie wp³ywu wdro¿enia nowych rozwi¹zañ na wydajnoœæ systemu.
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables



\chapter*{Wstêp}
\addcontentsline{toc}{chapter}{Wstêp}
W wielu wspó³czesnych systemach kopii zapasowych w¹skim gard³em procesu replikacji jest przesy³anie danych ³¹czem internetowym. W minimalizacji ich rozmiaru niew¹tpliwie pomaga dzielenie strumienia danych na bloki zmiennej d³ugoœci i u¿ywanie haszowania do eliminacji duplikatów.
\\*
Jednak to podejœcie ma swoje ograniczenia. W przypadku du¿ego rozmiaru bloku jest bardzo prawdopodobne, ¿e znajd¹ siê 2 prawie identyczne bloki, a istniej¹cy system tego nie wykryje i bêdzie przechowywa³ oba, co jest zachowaniem dalekim od optymalnego.
Sposobem na poprawienie tej sytuacji jest zastosowanie delta kodowania z u¿yciem indeksu podobieñstwa. Metoda ta polega na obliczaniu cech ka¿dego unikalnego bloku, a przy dodawaniu nowego bloku sprawdzaniu, czy istnieje blok podobny do niego. Miêdzy podobnymi blokami mo¿na obliczyæ ró¿nicê, której rozmiar zazwyczaj jest zdecydowanie mniejszy od rozmiaru ca³ego bloku.
\\*
Zastosowanie tego pomys³u w istniej¹cym systemie kopii zapasowych wymaga ogromnych nak³adów pracy i nie daje ¿adnych gwarancji. Z tego powodu na zlecenie firmy 9LivesData stworzyliœmy symulator systemu HYDRAstor, aby du¿o mniejszym wysi³kiem uzyskaæ informacjê, jakiego rzêdu zysku nale¿y siê spodziewaæ.
\\*
Stworzony symulator pozwala na badanie wp³ywu kilku czynników na iloœæ przesy³anych danych. Badane mo¿e byæ znaczenie kompresji, rozmiaru bloku, a przede wszystkim samego delta kodowania. Jednoczeœnie symulator stosuje mechanizmy oryginalnego systemu: dzielenie na bloki zmiennej d³ugoœci i wykrywanie duplikatów.

\chapter{System HYDRAstor}
HYDRAstor to nowoczesny, rozproszony, skalowalny system kopii zapasowych u¿ywaj¹cy dysku.
Jest jednym z najwiêkszych i najszybszych takich systemów na œwiecie u¿ywanym przez klientów w Japonii i Stanach Zjednoczonych.
Zosta³ stworzony, aby dostarczyæ klientom funkcjonalnoœci takie, jak: deduplikacja, mo¿liwoœæ konfiguracji wed³ug potrzeb. Ci¹g³e aktualizacje nie przerywaj¹ dzia³ania produktu. Ponadto system charakteryzuje siê du¿¹ odpornoœci¹ na b³êdy (patrz \cite{HYDRAstor}).
\\*
HYDRAstor jest niezwykle z³o¿ony i skomplikowany, dlatego stworzony przez nas symulator uwzglêdnia jedynie jego kluczowe dla naszego problemu w³asnoœci.
Na sekwencji rysunków zosta³a oddana idea dzia³ania systemu.
Nale¿y opowiedzieæ o najwa¿niejszych z naszego punktu widzenia elementach systemu: blokach zmiennej d³ugoœci, deduplikacji i kompresji.
\section{Bloki zmiennej d³ugoœci}
Bloki zmiennej d³ugoœci pozwalaj¹ w znacznym stopniu zmniejszyæ rozmiar danych, które zostan¹ przes³ane podczas replikacji, czyli procesu tworzenia nowej kopii. Za³ó¿my chwilowo, ¿e stosujemy bloki sta³ej wielkoœci i mamy na serwerze strumieñ danych o bardzo du¿ym rozmiarze. Nastêpnie w œrodku tego strumienia zostaje dodany jeden znak. Sprawia to, ¿e po³owa strumienia zostanie podzielona na zupe³nie nowe bloki, mimo ¿e dane siê praktycznie nie zmieni³y.
\\*
Stosowanie bloków zmiennej d³ugoœci w po³¹czeniu z komponentem zwanym Chunkerem, który wybiera granice bloków na podstawie samych danych, stosuj¹c pewne heurystyki, pozwala unikn¹æ tego problemu. W powy¿szym przyk³adzie zadzia³a³by tak, ¿e kilka bloków po nowym znaku by³oby innych, ale reszta nie zmieni³aby siê.
\section{Deduplikacja}
Dla ka¿dego z nowo dodanych bloków jest tworzony identyfikator za pomoc¹ jednej z popularnych funkcji skrótu. Pozwala to na eliminacjê duplikatów ze zbioru przechowywanych bloków. Ma to du¿e znaczenie praktyczne, jeœli kopie s¹ wykonywane czêsto i dane w wiêkszoœci siê nie zmieniaj¹.
\section{Kompresja}
Przed przes³aniem bloki s¹ poddawane dzia³aniu algorytmowi kompresji, co pozwala znacz¹co zmieniæ rozmiar danych. Stosowany algorytm kompresji musi nie tylko mieæ dobry wspó³czynnik kompresji, ale te¿ nie zu¿ywaæ zbyt du¿o zasobów systemu.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/visualization/1.png}
    \caption{Z systemu A chcemy przes³aæ do systemu B dane.}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/visualization/2.png}
    \caption{System A dzieli dane na bloki, dla ka¿dego z bloków liczy wartoœæ funkcji skrótu. Zauwa¿my, ¿e dla identycznych bloków dostajemy takie same wartoœci.}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/visualization/3.png}
    \caption{System A przesy³a do systemu B informacje o po³o¿eniu kolejnych bloków (tj. ci¹g identyfikatorów) oraz zawartoœci bloków z pominiêciem duplikatów (deduplikacja).}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/visualization/4.png}
    \caption{System B posiada teraz te same bloki co system A.}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/visualization/5.png}
    \caption{System A chce przes³aæ do systemu B kolejn¹ wersjê danych.}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/visualization/6.png}
    \caption{System A dzieli dane na bloki i liczy wartoœci funkcji skrótu. Zauwa¿my, ¿e zmieni³y siê tylko dwa bloki, co jest zas³ug¹ Chunkera.}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/visualization/7.png}
    \caption{System A przesy³a do systemu B informacje o rozmieszczeniu bloków oraz zawartoœci jedynie tych bloków, które s¹ nowe. Znacz¹co zmniejsza to objêtoœæ przesy³anych danych.}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/visualization/8.png}
    \caption{System B odbiera nowe dane i posiada teraz takie same bloki, co system A.}
\end{figure}

\chapter{Delta kodowanie}
System HYDRAstor, mimo wielu niew¹tpliwych zalet, mo¿e byæ znacznie bardziej wydajny.
Iloœæ danych niezbêdnych do przes³ania z kolejn¹ wersj¹ mo¿e ulec znacznemu zmniejszeniu dziêki algorytmom delta kodowania.
\\*
Delta kodowanie to sposób przechowywania i transmisji danych w formie ró¿nic (ang. \textit{delta}) pomiêdzy blokami danych.
W sytuacjach, gdy ró¿nice pomiêdzy blokami s¹ ma³e, delta kodowania potrafi znacznie zmniejszyæ nadmiarowoœæ.
Przechowywanie zbioru ró¿nic jest zdecydowanie bardziej efektywne pamiêciowo ni¿ przechowywanie ca³ych bloków.
Oczywiœcie, na ich wielkoœæ ma bardzo du¿y wp³yw to, które dane ze sob¹ porównujemy, a tak¿e jakiego u¿ywamy algorytmu do liczenia ró¿nic.
Dlatego delta kodowanie mo¿na sprowadziæ do dwóch zasadniczych problemów: znajdowania podobnych bloków i liczenia ró¿nic miêdzy nimi.
\section{Liczenie ró¿nic}
Jest to popularny w informatyce problem, aby na podstawie dwóch fragmentów danych stworzyæ ró¿nicê (ang. \textit{delta}), dziêki której maj¹c tylko pierwszy fragment i ow¹ ró¿nicê, mo¿na  by³o odtworzyæ drugi fragment. Oczywiœcie rola fragmentów nie jest symetryczna - liczymy ró¿nicê jednego wzglêdem drugiego. Powsta³ szereg algorytmów, które siê tym zajmuj¹.
\\*
Jeden z nich implementuje popularny program Diff z systemów Unix. Jednak nie jest dobrym rozwi¹zaniem dla naszego problemu, gdy¿ porównuje pliki na poziomie linii, co ma szanse siê sprawdziæ jedynie dla specyficznego rodzaju plików tekstowych.
\\*
Interesuj¹ nas przede wszystkim algorytmy przeznaczone do liczenia ró¿nic miêdzy danymi binarnymi. Ograniczymy siê jednak do algorytmu xdelta3, którego u¿ywamy w symulatorze.
W du¿ym uproszczeniu jego dzia³anie polega na odtwarzaniu po kolei pliku, wykonuj¹c kilka operacji:
\begin{itemize}
\item wstawienie danego ci¹gu bajtów
\item skopiowanie ci¹gu bajtów z odtworzonego ju¿ fragmentu
\item skopiowanie ci¹gu bajtów z bazowego fragmentu
\end{itemize}

\section{Znajdowanie podobnych bloków}
W symulatorze zaimplementowaliœmy dwa ró¿ne podejœcia do tego problemu.
\subsection{Algorytm optymalny}
W algorytmie optymalnym porównujemy nowy blok ze wszystkimi blokami, które posiadamy. Jest on niemo¿liwy do zastosowania w praktyce przez asymptotycznie kwadratowy czas dzia³ania ze wzglêdu na iloœæ bloków. Jednak jest on dobrym punktem odniesienia do innych algorytmów - daje on informacjê, jakie jest dolne ograniczenie na rozmiar danych w klasie algorytmów delta kodowania porównuj¹cych z jednym blokiem.
\begin{algorithmic}
\Function{optimalDeltaEncoding}{$blocks, block$}
\State $best\_block \gets blocks[0]$
\State $best\_diff \gets \Call{Diff}{block, blocks[0]}$
\For{$old\_block \ \textbf{in} \ blocks$}
    \State $diff \gets \Call{Diff}{block, old\_block}$
    \If{$\Call{length}{diff} < \Call{length}{best\_diff}$}
        \State $best\_diff \gets diff$
        \State $best\_block \gets old\_block$
    \EndIf
\EndFor
\State \Return $best\_block.getHash()$
\EndFunction
\end{algorithmic}
\subsection{Algorytm z indeksem podobieñstwa}
W algorytmie z indeksem podobieñstwa stosujemy zdecydowanie bardziej wyrafinowan¹ strategiê. Dla ka¿dego bloku bêdziemy liczyæ okreœlon¹, sta³¹ iloœæ $K$ wartoœci liczbowych zwanych cechami (ang. \textit{feature}). W tym celu poruszamy siê po bloku oknem (ang. \textit{window}) o sta³ym rozmiarze $W$ i dla ka¿dego okna $w$ liczymy znacznik Rabina (ang. \textit{Rabin’s fingerprint}) $fp(w) = \sum\limits_{i=0}^{W-1} w[i] \times P^{i} \mod Q$, gdzie $P$ i $Q$ to ustalone liczby pierwsze. Dla cechy o numerze $i$ definiujemy dwie wartoœci $m_i$ oraz $a_i$. Wartoœci¹ cechy o numerze $i$ bêdzie minimum po wszystkich oknach $w$ z $(fp(w) * m_i + a_i) \mod 2^{32}$. Wartoœciami $a_i$ oraz $m_i$ powinny byæ du¿e, losowe liczby pierwsze, jednak w celu zapewnienia powtarzalnoœci eksperymentów s¹ one w naszym symulatorze ustalone. Nastêpnie tworzymy supercechy (ang. \textit{superfeature}) z ustalonej liczby $S$ zwyk³ych cech. W tym celu dzielimy cechy danego bloku na grupy po $K$ kolejnych cech i dla ka¿dej z grup liczymy znacznik Rabina - jego wartoœæ bêdzie wartoœci¹ danej supercechy. Wszystkie znaczniki liczymy przy u¿yciu du¿ych liczb pierwszych $P$ i $Q$. Aby znaleŸæ podobny blok do danego, wybieramy taki, który ma najwiêcej wspólnych super cech (jeœli jest takich wiêcej, wybieramy dowolny). Jeœli zaœ nie ma bloku z jak¹kolwiek wspóln¹ super cech¹, wysy³amy ca³y blok. Eksperymentalnie wyznaczyliœmy, ¿e najlepiej dzia³aj¹ wartoœci $K=4$ i $S=2$ - pod uwagê braliœmy iloœæ czasu potrzebn¹ na obliczenia, iloœæ znajdowanych bloków oraz ich jakoœæ. Oczywiœcie, im wiêksze $K$, tym lepsza jakoœæ kandydatów. Z kolei, im wiêksze $S$, tym wiêcej bloków znajdujemy. Czas obliczeñ jest zaœ wprost proporcjonalny do $S \times K$.

\begin{algorithmic}
\Function{calculateFeatures}{$block$}
\State $N \gets S \times K$
\State $features[N] \gets {None, ... }$
\State $best[N] \gets {2^{32}, ... }$
\ForAll{window $w$ in $block$}
    \For{$i \ \textbf{in} \ \{0, ..., N\}$}
        \State $value \gets m[i] \times \Call{fp}{w} + a[i] \mod 2^{32}$
        \If {$value < best[i]$}
            \State $best[i] \gets value$
            \State $feature[i] \gets \Call{fp}{w}$
        \EndIf
    \EndFor
\EndFor
\State \Return $features$
\EndFunction
\\
\Function{similarityIndexEncoding}{$block, hashes\_map, sfeatures\_map$}
\State $features \gets \Call{calculateFeatures}{block}$
\State $sfeatures \gets \Call{createSuperfeatures}{features}$
\State $hashes \gets empty$ \Comment{wartoœci funkcji skrótu kandydatów na blok bazowy}
\For{$sfeature \ \textbf{in} \ sfeatures$}
    \State $hashes.add(hashes\_map[sfeature])$
\EndFor
\State $best \gets None$ \Comment{szukanie bloku z najwiêksz¹ iloœci¹ wspólnych supercech}
\State $common \gets 0$
\For{$hash \ \textbf{in} \ hashes$}
    \State $common' \gets \Call{length}{sfeatures.intersect(sfeatures\_map[hash])}$
    \If {$common' > common$}
        \State $common \gets common'$
        \State $best \gets hash$
    \EndIf
\EndFor
\State $sfeatures\_map.add(block.getHash(), sfeatures)$ \Comment{aktualizowanie struktur danych}
\For{$sfeature \ \textbf{in} \ sfeatures$}
    \State $hashes\_map.add(sfeature, block.getHash())$
\EndFor
\State \Return $best$
\EndFunction
\end{algorithmic}

\chapter{Architektura}
Aby sprawdziæ algorytmy delta kodowania, stworzyliœmy symulator systemu HYDRAstor.
Jego architektura oparta jest o wzorzec Model-View-Controller, zapewniaj¹cy niezale¿noœæ kodu odpowiedzialnego za interakcjê z u¿ytkownikiem od kodu zajmuj¹cego siê logik¹ biznesow¹ aplikacji. Oprócz standardowych dla wzorca MVC czêœci: model, widok i kontroler w architekturze naszego projektu mo¿emy wyró¿niæ Storage - osobn¹ czêœæ odpowiedzialn¹ za sk³adowanie danych w trakcie trwania symulacji oraz Chunker - czêœæ przetwarzaj¹c¹ pliki z dysku twardego. Zale¿noœci miêdzy poszczególnymi komponentami pokazane s¹ na poni¿szym schemacie.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{img/Architecture.png}
    \caption{Schemat architektury}
    \label{fig:architecture}
\end{figure}

\section{Model-View-Controller}
Wzorzec Model-View-Controller zosta³ zaimplementowany w standardowy sposób. Wiêkszoœæ modeli by³a pasywna, czyli nie zmienia³a swojego stanu samoczynnie. Zaraz po tym jak kontroler modyfikowa³ jakiœ model, powiadamia³ on odpowiedni widok o zmianie. Mechanizm ten zosta³ zaimplementowany przy u¿yciu sygna³ów biblioteki wxPython - wx.Event. Kolejka reprezentuj¹ca kolejne zadania do wykonania by³a modelem aktywnym, czyli takim który mo¿e zmieniæ swój stan niezale¿nie od akcji wykonywanych przez u¿ytkownika. Do jego obs³ugi zastosowaliœmy bibliotekê Publisher pakietu wxPython. Pozwala ona na wysy³anie komunikatów do kontrolera gdy kolejka ulega zmianie.

\section{Chunker}
Chunker jest osobnym modu³em zajmuj¹cym siê dzieleniem plików na bloki zmiennej d³ugoœci w taki sposób, aby wprowadzenie modyfikacji w pliku nie wymaga³o przes³ania du¿ej iloœci danych. Zosta³ nam dostarczony przez firmê 9LivesData.

\section{Storage}
Storage odpowiada za gromadzenie bloków danych powsta³ych w trakcie fazy dzielenia plików przez Chunker. Ta czêœæ symulatora jest odpowiedzialna równie¿ za wykrywanie duplikatów bloków oraz ich zliczanie. Wykrywanie duplikatów zosta³o zaimplementowane przy u¿yciu funkcji skrótu SHA-256.

\chapter{Funkcjonalnoœci}
Symulator zosta³ stworzony, aby szybko i wygodnie przeprowadzaæ eksperymenty na rzeczywistych danych.
Zosta³o w³o¿one wiele trudu, by by³ intuicyjny i by spe³nia³ wszystkie wymagania.
W rezultacie posiada on szereg wymienionych ni¿ej funkcjonalnoœci.
\begin{itemize}
        \item
        Mo¿liwoœæ wyboru sposobu przechowywania danych.
        
        Wybiera siê miêdzy u¿ywaniem wy³¹cznie pamiêci RAM a wykorzystaniem bazy danych. Pozwala to na wykonywanie ma³ych testów w pamiêci (co je znacz¹co przyspiesza), a du¿ych z wykorzystaniem dysku (w przeciwnym razie nie starczy³oby pamiêci).	
	
        \item
        Symulowanie replikacji bez u¿ycia delta kodowania, z u¿yciem optymalnego delta kodowania oraz z heurystycznym delta kodowaniem.
        
	Symulator pozwala na przetestowanie zaimplementowanych algorytmów oraz udostêpnia intuicyjny interfejs programistyczny dziêki czemu mo¿na w prosty sposób rozszerzaæ o kolejne algorytmy.
        \item
        Kompresja danych przed przes³aniem.
        
	Po zastosowaniu odpowiedniego algorytmu dane przed wys³aniem mog¹ byæ dodatkowo kompresowane przy pomocy LZO, ZIP lub LZMA.
        \item
        Wygodny graficzny interfejs u¿ytkownika
	
	Za pomoc¹ graficznego interfejsu u¿ytkownik mo¿e wybraæ interesuj¹ce go konfiguracje, które chce przetestowaæ oraz wygenerowaæ wykres przedstawiaj¹cy wyniki.
	
	\item
	Kolejkowanie eksperymentów.
	
	Interfejs graficzny pozwala na dodawanie dowolnej liczby eksperymentów, które wykonuj¹ siê po kolei.
	
	\item
	Prezentacja wyników w formie wykresów.
	
	Wyniki wykonanych symulacji mo¿na wyœwietliæ w postaci interaktywnych wykresów.
	S¹ one œwietnym narzêdziem, które umo¿liwia zbadanie faktycznych rezultatów symulacji.
	\item
	Serializacja wyników danych.
	
	W celu zwiêkszenia elastycznoœci i ergonomii symulatora mo¿na wczytywaæ i zapisywaæ do pliku wyniki wybranych eksperymentów.
\end{itemize}
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/app1.png}
    \caption{Ekran tworzenia eksperymentu}
    \label{fig:experiment_screen}
\end{figure}	
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/app2.png}
    \caption{Ekran tworzenia wykresu}
    \label{fig:chart_screen}
\end{figure}



\chapter{Technologie}
Bardzo du¿e znaczenie dla jakoœci systemu informatycznego maj¹ zastosowane technologie.
Ich wybór ma wp³yw na wydajnoœæ, ³atwoœæ pisania kodu, dostêpnoœæ bibliotek (w przypadku jêzyka programowania).
Podobnie by³o w przypadku symulatora, co zostanie pokazane w nastêpnych paragrafach.
\section{Jêzyki programowania}
W jêzyku C++ napisaliœmy adapter Chunkera.
By³o to wymuszone technologi¹, w jakiej zosta³ napisany ten komponent.
\\*
Sam symulator zdecydowaliœmy siê napisaæ w jêzyku Python w wersji 2.7.
Wybraliœmy go ze wzglêdu na na mo¿liwoœæ szybkiego wytwarzania oprogramowania przy stosunkowo niewielkiej iloœci kodu Ÿród³owego.
Jednoczeœnie jest w nim dostêpnych wiele ró¿norodnych bibliotek, z których chcieliœmy skorzystaæ w naszym projekcie.
Niestety, Python przy wszystkich swoich zaletach nie oferuje zbyt dobrej wydajnoœci.
Dlatego wymagaj¹ce obliczeniowo czêœci algorytmów zosta³y napisane w C.
Zrobiliœmy to, u¿ywaj¹c zbioru nag³ówków implementacji CPython.
Pozwoli³o to przyspieszyæ symulacjê kilkanaœcie razy.
\\*
Byæ mo¿e warto wyjaœniæ, dlaczego nie zdecydowaliœmy siê na wersjê Pythona z prefiksem 3.
Otó¿ nie jest ona kompatybilna wstecznie i dlatego u¿ycie wielu bibliotek, które s¹ dostêpne dla wersji 2.7, staje siê problematyczne.
Poza tym, mieliœmy wiêcej doœwiadczenia z u¿ywaniem poprzednich wersji.
\\*
Mo¿e siê równie¿ nasuwaæ pytanie, dlaczego nie zastowaliœmy implementacji Pythona o nazwie PyPy.
Jest ona wszak du¿o bardziej wydajna ni¿ popularny CPython.
Niestety, u¿ywanie wielu pakietów, które zosta³y napisane w C (np. wxPython) jest w niej siê trudne lub wrêcz niemo¿liwe.
Poza tym, nie jest ona do koñca kompatybilna z innymi implementacjami.
\section{Biblioteki}
\subsection{wxPython}
Obs³uga symulatora odbywa siê za pomoc¹ graficznego interfejsu u¿ytkownika stworzonego z u¿yciem pakietu wxPython.
Zosta³ zaimplementowany jako nak³adka na napisan¹ w C++ bibliotekê wxWidgets.
Warto wspomnieæ, ¿e jest on wieloplatformowy.
\subsection{Pygal}
Biblioteka ta umo¿liwia tworzenie wykresów w formacie SVG na podstawie ró¿norodnych statystyk opisuj¹cych wyniki eksperymentu.
\subsection{Virtualenv}
Jest to narzêdzie do tworzenia izolowanego œrodowiska dla aplikacji w Pythonie.
Umo¿liwia ono posiadanie lokalnych instalacji wielu bibliotek, które mog¹ byæ ró¿ne od tych zainstalowanych globalnie.
Dziêki temu nasz symulator jest niezale¿ny od systemowych aktualizacji, a tak¿e od innych aplikacji w obrêbie systemu
\subsection{Xdelta}
U¿yliœmy tej biblioteki w wersji 3 do liczenia ró¿nic miêdzy plikami binarnymi.
Zosta³a napisana w C, co ma du¿y wp³yw na wydajnoœæ.
\subsection{Pylint}
Narzêdzie do statycznej analizy kodu Ÿród³owego, które zdecydowanie u³atwia dbanie o jego jakoœæ.
Sprawdza zgodnoœæ z zaleceniami PEP 8.
\subsection{PyLZMA}
Biblioteka do kompresji LZMA.

\section{Baza danych}
Wybraliœmy LevelDB, jest to nierelacyjna baza danych, która umo¿liwia efektywne przechowywanie danych typu klucz-wartoœæ. W naszym przypadku ma miejsce odwzorowanie wartoœci funkcji skrótu w odpowiadaj¹cy jej blok. Zastosowanie bazy danych pozwoli³o nam na wykonywanie eksperymentów, których rozmiar danych wejœciowych przekracza³ wielokrotnie rozmiar pamiêci RAM. Dziêki temu mogliœmy sprawdziæ jak zachowuj¹ siê algorytmy dla znacznie wiêkszych danych.

\chapter{Wyniki symulacji}
W tym rozdziale zostan¹ przedstawione i omówione rezultaty eksperymentów na danych ró¿nych typów.
Przygotowanie danych do testowania by³o istotn¹ czêœci¹ pracy. Dobrze dobrane dane testowe pozwalaj¹ na lepsze zrozumienie dzia³ania algorytmów.
Dziêki nim mo¿na oszacowaæ zysk, który zostanie osi¹gniêty w systemie HYDRAstor.
\section{Format wyników}
Wyniki s¹ przedstawione w formie wykresów s³upkowych. Jeden kolor odpowiada jednej metodzie przesy³ania danych. Wybór metody obejmuje jednoczeœnie algorytm delta kodowania (np. algorytm optymalny) oraz rodzaj kompresji (np. LZMA). Wysokoœæ ka¿dego s³upka okreœla, ile danych trzeba przes³aæ dla danej wersji danych wejœciowych.

\section{Wyniki dla Ÿróde³ j¹dra Linuxa - ma³e odstêpy}
Pierwsza symulacja zosta³a przeprowadzona dla Ÿróde³ j¹dra Linuxa. Zosta³y przygotowane trzy wersje Ÿróde³ j¹dra Linuxa z ró¿nicami 5 tysiêcy zmian pomiêdzy ka¿dymi dwiema kolejnymi. Rozmiar danych potrzebnych do przes³ania zosta³ policzony dla szeœciu metod.
\\*
Znaczenie kolorów:

\begin{itemize}
\item Czerwony - usuwanie duplikatów, brak kompresji
\item Zielony - usuwanie duplikatów, kompresja LZO. Warto dodaæ, ¿e jest to obecny wynik systemu HYDRAstor
\item ¯ó³ty - usuwanie duplikatów, kompresja LZMA
\item B³êkitny - indeks podobieñstwa, brak kompresji
\item Fioletowy- indeks podobieñstwa, kompresja LZO
\item Szary - indeks podobieñstwa, kompresja LZMA
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/linuxSmall.png}
    \caption{Wyniki dla Ÿróde³ j¹dra Linuxa z ma³ymi odstêpami}
    \label{fig:linuxSmall}
\end{figure}

Na wykresie s¹ widoczne trzy grupy, ka¿da grupa sk³adaj¹ca siê z szeœciu s³upków. Pierwsza grupa pokazuje, ile danych trzeba przes³aæ dla pierwszej wersji przy u¿yciu konkretnej metody, druga grupa dla drugiej wersji itd. 
\\*
Zacznijmy od iloœci duplikatów, które zosta³y wykryte wœród bloków. Dla pierwszej wersji jest to 0.05\%, wiêc bardzo ma³o. Dla drugiej wersji duplikaty stanowi¹ 8.05\% bloków. Pomimo tego, ¿e wersje by³y od siebie oddalone o tylko 5 tysiêcy zmian, wiêkszoœæ bloków zosta³a zmieniona.  Dla trzeciej wersji liczba usuniêtych duplikatów to nieco ponad 10\%. Jest to niewiele lepszy wynik.
\\*
Przeanalizujmy najpierw kolory czerwony, zielony i ¿ó³ty. Wszystkie dotycz¹ metody, w której jedynie usuwa siê duplikaty, ró¿ni¹ siê jedynie algorytmem kompresji u¿ytym przed wys³aniem danych. Widzimy, ¿e kompresja LZO zmniejsza rozmiar danych prawie o 85\%. Z kolei zastosowanie LZMA daje dla pierwszej wersji oszczêdnoœæ oko³o 41\% w stosunku do LZO. Widaæ zatem, ¿e warto rozwa¿yæ u¿ycie znacznie bardziej kosztownego obliczeniowo algorytmu LZMA. Podobne wnioski mo¿na wyci¹gn¹æ patrz¹c na drug¹ i trzeci¹ wersjê Ÿróde³ j¹dra linuxa. W ka¿dym przypadku algorytm LZMA znacznie zmniejszy³ rozmiar danych koniecznych do wys³ania.
\\*
Drug¹ u¿yt¹ metod¹ jest indeks podobieñstwa. Dla pierwszej wersji wyniki samego usuwania duplikatów z ró¿nymi algorytmami kompresji (kolory czerwony, zielony, ¿ó³ty) prawie idealnie odpowiadaj¹ metodzie z u¿yciem indeksu podobieñstwa (kolory b³êkitny, fioletowy, szary). Wynika to z tego, ¿e indeks podobieñstwa nie mia³ danych do których móg³by porównywaæ.
Jednak do przes³ania drugiej i trzeciej wersji Ÿróde³ linuxa rozmiar wynikowych danych jest znacznie mniejszy. Odpowiednio dla standardowej metody i kompresji LZO - 57MB a dla indeksu podobieñstwa 26MB. Oznacza to zmniejszenie danych o ponad 50\%! Podobny wynik mo¿na zaobserwowaæ dla trzeciej wersji.
\\*
Równie¿ dla metody indeksu podobieñstwa zysk z u¿ycia algorytmu kompresji LZMA jest znaczny. Dla kolejnych wersji mamy odpowiednio zmniejszenie rozmiaru o 41\%, 34\% oraz 34\%.
\section{Wyniki dla Ÿróde³ j¹dra Linuxa - du¿e odstêpy}
Druga symulacja zosta³a przeprowadzona równie¿ dla Ÿróde³ j¹dra Linuxa. Dane jednak znacznie siê ró¿ni¹ od siebie - ka¿da kolejna wersja jest odleg³a od poprzedniej o 20 tysiêcy zmian. Powoduje to, ¿e kolejne wersje maj¹ ze sob¹ zdecydowanie mniej wspólnego. Znaczenie kolorów jest takie same jak ostatnio.
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/linuxBig.png}
    \caption{Wyniki dla Ÿróde³ j¹dra Linuxa z du¿ymi odstêpami}
    \label{fig:linuxBig}
\end{figure}
\\*
Na pocz¹tku warto zauwa¿yæ, ¿e liczba duplikatów jest znacznie mniejsza. Dla drugiej i trzeciej wersji znaleziono mniej ni¿ 2\% podobnych bloków. Niestety, w tym przypadku indeks podobieñstwa te¿ niewiele pomaga.
\\*
Wyniki s¹ znacznie gorsze ni¿ w poprzednim eksperymencie. Porównajmy metody oznaczone kolorem zielonym i fioletowym. Obie u¿ywaj¹ tego samego algorytmu kompresji, wiêc ró¿ni¹ siê tylko algorytmem delta kodowania. Dla pierwszej wersji zysk z u¿ycia indeksu podobieñstwa jest prawie zerowy (dok³adnie tak, jak poprzednio). Dla drugiej i trzeciej wersji zysk wynosi odpowiednio 15\% i 9\%. Jeszcze gorzej prezentuje siê porównanie tych metod gdy u¿ywamy algorytmu LZMA (kolory ¿ó³ty i szary), dane zosta³y zmniejszone odpowiednio o 11\% oraz 7\% dla drugiej i trzeciej wersji Ÿróde³ j¹dra linuxa. Warto dodaæ, ¿e po raz kolejny kompresja LZMA znacznie zmniejszy³a dane konieczne do wys³ania, œrednio o 40\%.
\section{Wyniki dla kopii zapasowych katalogu domowego}
Tym razem eksperyment dotyczy³ danych, które pochodzi³y z naszych katalogów domowych.
Oznaczenie kolorów jest identyczne jak poprzednio. W przypadku katalogów domowych deduplikacja dzia³a znacznie lepiej. Dla drugiej i trzeciej wersji katalogu domowego (s¹ one oddalone o oko³o miesi¹c u¿ytkowania) liczba duplikatów to odpowiednio 64\% oraz 75\%. Jest to bardzo dobry wynik. Jest to spowodowane specyfik¹ sposobu u¿ytkowania katalogu domowego. W katalogu domowym czêsto pojawiaj¹ siê nowe dane b¹dŸ jakieœ dane s¹ usuwane. Bardzo rzadko zdarzaj¹ siê modyfikacje pojedynczego dokumentu. To mo¿e t³umaczyæ, dlaczego metoda indeksu podobieñstwa nie daje ¿adnego zysku. Przy jej u¿yciu musielibyœmy przesy³aæ tyle samo danych co w przypadku obecnej wersji systemu HYDRAstor.
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/backups.png}
    \caption{Wyniki dla kopii zapasowych katalogu domowego}
    \label{fig:backup}
\end{figure}

\section{Wyniki dla Ÿróde³ ma³ego projektu torch}
Interesuj¹cym mo¿e wydaæ siê pytanie, jak indeks podobieñstwa dzia³a w porównaniu z optymalnym algorytmem delta kodowania. Pokazuje to kolejny eksperyment.
\\*
Znaczenie kolorów:
\begin{itemize}
\item Jasnoczerwony - usuwanie duplikatów, kompresja LZO
\item Zielony - optymalny algorytm delta kodowania, kompresja LZO
\item ¯ó³ty - indeks podobieñstwa, kompresja LZO
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/torch.png}
    \caption{Wyniki dla projektu torch}
    \label{fig:torch}
 \end{figure}
Niestety, dane s¹ bardzo ma³e ze wzglêdu na kwadratow¹ z³o¿onoœæ algorytmu optymalnego delta kodowania.
Jednak dziêki temu mo¿emy porównaæ algorytm optymalny z indeksem podobieñstwa.
Pozwala to zobaczyæ, jakie jest dolne ograniczenie na iloœæ przes³anych danych dla indeksu podobieñstwa.
Dla drugiej wersji algorytm optymalny przygotowa³ o 54\% mniej danych do przes³ania, a dla trzeciej wersji o 41\% mniej.
Oznacza to, ¿e daleko algorytmowi z indeksem podobieñstwa do optymalnoœci.

\chapter{Organizacja pracy}

\section{System kontroli wersji}
Tworzony przez nas symulator jest rozwijany za pomoc¹ systemu kontroli
wersji git. Korzystamy ze zdalnego repozytorium w serwisie github.com.
\section{Metodyka pracy}
Pracujemy w metodyce agile z dodatkiem kanbana. Zespó³ spotyka siê co tydzieñ,
aby ustaliæ priorytety na najbli¿szy czas, podzieliæ siê prac¹ i omówiæ
wyniki dotychczasowych dzia³añ. Otrzymujemy odgórne wytyczne
co do kszta³tu symulatora od 9LivesData ("du¿e zadania"),
które realizujemy mniejszymi fragmentami ("ma³e zadania"). Ka¿de z
mniejszych zadañ jest realizowane przez jednego cz³onka zespo³u.
\section{Realizacja pojedynczego zadania}
Zadanie jest wybierane przez cz³onka zespo³u, tworzona jest oddzielna
ga³¹Ÿ, pisane s¹ testy, a nastêpnie zadanie jest realizowane. PóŸniej kod podlega
inspekcji przeprowadzonej przez innego cz³onka zespo³u.
Przy koniecznoœci wprowadzenia poprawek kod wraca do autora i s¹ one
przez niego nanoszone. Po inspekcji zakoñczonej sukcesem autor w³¹cza kod
do g³ównej ga³êzi projektu.
\section{Tworzenie oprogramowania oparte o testy}
Stosujemy tzw. TDD (ang. \textit{Test Driven Development}) - przed napisaniem fragmentu
kodu programista materializuje wymagania funkcjonalne jako testy jednostkowe
pocz¹tkowo ponosz¹ce pora¿kê,
a nastêpnie doprowadza kod do takiego stanu, aby owe testy koñczy³y siê z
sukcesem.
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/trello_screen.png}
    \caption{Platforma Trello do zarz¹dzania zadaniami}
    \label{fig:trello_screen}
\end{figure}

\section{Podzia³ pracy}

\begin{center}
    \begin{tabular}{ | l | p{10cm} |}
    \hline
    Cz³onek zespo³u & Wykonane zadania \\ \hline
    Krzysztof Kiewicz &
    Integracja mo¿liwoœci testowania ca³ych katalogów/wersji z GUI. \newline
    Refaktoryzacja GUI.
    
    \\ \hline
    Pawe³ Kura & 
    Zaimplementowanie domyœlnego dodawania danych do Storage'u (algorytm naiwny). \newline
    Zaimplementowanie klasy FileProcessor, przetwarzaj¹cej pliki i dodaj¹cej je do Storage'u. \newline
    Dodanie mo¿liwoœci testowania ca³ych katalogów i wersji.
    \newline
    Przygotowanie danych do testowania
      
    \\ \hline
    Dawid £azarczyk &
    Zaimplementowanie ca³ej komunikacji z Chunkerem \newline
    Dodanie interfejsów do ChunkUpdate. \newline
    Dodanie algorytmu diff. \newline
    Zaimplementowanie optymalnego algorytmu delta kodowania. \newline
    Generowanie wykresów dla wielu eksperymentów na raz. \newline
    Zaimplementowanie algorytmu z indeksem podobieñstwa \newline
    Zaimplementowanie serializacji wyników
    
    \\ \hline
    Marcel Ziêba &
    Przygotowanie œrodowiska - repozytorium, frameworka do testowania, statyczna analiza kodu, code review \newline
    Zaimplementowanie podstawowych klas odpowiadaj¹cych za przechowywanie danych. \newline
    Zaimplementowanie podstawowej wersji GUI. \newline
    Dodanie kompresji LZO i ZIP. \newline
    Dodanie mo¿liwoœci generowania i wyœwietlania wykresów w GUI. \newline
    Dodanie asynchronicznego wykonywania eksperymentów \newline
    Implementacja mierzenia kosztów operacji wejœcia-wyjœcia \newline
    Przeprowadzenie eksperymentów i opracowanie wyników
       
    \\ \hline
    \end{tabular}
\end{center}

\chapter{Podsumowanie}
Eksperymenty przeprowadzone w naszym symulatorze pokaza³y, ¿e jest sens analizowania i rozwijania algorytmów delta kodowania.Wybrany przez nas algorytm korzystaj¹cy z indeksu podobieñstwa daje rezultaty porównywalne z algorytmem optymalnym dla pewnych danych, np. kodów Ÿród³owych. Zysk wzglêdem algorytmu u¿ywaj¹cego jedynie deduplikacji jest zauwa¿alny zw³aszcza, gdy zosta³y przeprowadzone niewielkie zmiany w wielu plikach. Jednak dla innych danych mo¿e siê okazaæ, ¿e uzyskana redukcja rozmiaru danych jest na tyle ma³a, ¿e nie op³aca siê obci¹¿aæ systemu intensywnym obliczeniowo algorytmem delta kodowania. Niebagatelne znaczenie ma czêstoœæ wykonywania kopii zapasowych - im czêœciej siê je wykonuje, tym wiêksza szansa na znalezienie podobnych danych i tym samym wiêkszy zysk z delta kodowania.


\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem{work1} P. Shilane, M. Huang, G. Wallace, W. Hsu, \textit{WAN-optimized replication of backup datasets using stream-informed delta compression.} TOS 8(4): 13 (2012)

\bibitem{work2} P. Shilane, M. Huang, G. Wallace, W. Hsu, \textit{Delta Compressed and Deduplicated Storage
Using Stream-Informed Locality}, HotStorage (2012).

\bibitem{work3} T. Suel, N. Memon, \textit{Algorithms for Delta Compression and Remote File
Synchronization}, CIS Department
Polytechnic University
Brooklyn, NY 11201 (2002).

\bibitem{wxPython} wxPython Team, \textit{Dokumentacja wxPython}, \url{http://wxpython.org/Phoenix/docs/html/main.html} [21.01.2015r.]

\bibitem{xDelta} J. MacDonald \textit{xdelta}, \url{http://xdelta.org/} [21.01.2015r.]
\bibitem{HYDRAstor} 9LivesData \textit{HYDRAstor}, \url{http://www.9livesdata.com/hydrastor.html}

\end{thebibliography}

\appendix
\chapter*{Dodatek A}
Na p³ycie CD-ROM do³¹czonej do niniejszej pracy znajduj¹ siê:
\[
	\begin{tabular}{c|c}
		Kod Ÿród³owy symulatora wraz z testami & ./deltacompression/ \\ \hline
		Skrypt przygotowuj¹cy dane testowe & ./tools/ \\ \hline
		Dokumentacja instalacji & ./README.md \\ \hline
		Kod Ÿród³owy pracy licencjackiej & ./thesis/
	\end{tabular}
\]

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
